{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: A notebook example for generating settings and calibration files for\n",
    "  the OpenHSI camera.\n",
    "output-file: calibrate_steps.html\n",
    "skip_exec: true\n",
    "skip_showdoc: true\n",
    "title: Generating Calibration Files\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "GEN_CAL_FILES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-warning}\n",
    "\n",
    "This is not for general use. Requires technical expertise.\n",
    "\n",
    ":::\n",
    "\n",
    "Tools required: \n",
    "- An integrating sphere (we use a Spectra PT from LabSphere)\n",
    "- A HgAr lamp\n",
    "\n",
    "Adjust the camera class as needed. This example uses the `LucidCamera`. The are some LucidCamera specifc items in the below code that would need to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "\n",
    "from openhsi.calibrate import SettingsBuilderMixin, SpectraPTController, sum_gaussians\n",
    "from openhsi.cameras import LucidCamera\n",
    "\n",
    "hv.extension(\"bokeh\", logo=False)\n",
    "import panel as pn\n",
    "\n",
    "\n",
    "class CalibrateCamera(SettingsBuilderMixin, LucidCamera):\n",
    "    pass\n",
    "\n",
    "json_path_template = \"../cals/cam_settings_lucid_template.json\"\n",
    "cal_path = \"\"\n",
    "\n",
    "modelno = 18\n",
    "\n",
    "print(\"\".format(modelno))\n",
    "\n",
    "json_path_target = \"../cals/OpenHSI-{0:02d}/OpenHSI-{0:02d}_settings_Mono8_bin1.json\".format(\n",
    "    modelno\n",
    ")\n",
    "cal_path_target = \"../cals/OpenHSI-{0:02d}/OpenHSI-{0:02d}_calibration_Mono8_bin1.pkl\".format(\n",
    "    modelno\n",
    ")\n",
    "\n",
    "if not os.path.isdir(os.path.dirname(json_path_target)):\n",
    "    os.mkdir(os.path.dirname(json_path_target))\n",
    "\n",
    "spt = SpectraPTController()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find illuminated sensor area\n",
    "\n",
    "The vertical directon/y axis of the detector array corrspeonds the across-track direction of the sensor. If the image of slit is shorter then the heigh we can crop the top and bottom to save bandwidth/disk space (similar to letterboxing video).\n",
    "\n",
    "There are two ways to do this, croping after the fact using row_minmax or by setting up a window on the sensor. Setting up a window will reduce the ammount of data transfered from the sensor and can improve maximum framerate depending on the sensor so is recomended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Take a flat field\n",
    "\n",
    "First step is to provide a uniform illumination to the slit, ideally spectrally broadband, like a halogen lamp or the sun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select luminance value 10000 on the SpectraPT\n",
    "spt.selectPreset(10000)\n",
    "\n",
    "# Initialize the CalibrateCamera class with specified parameters\n",
    "with CalibrateCamera(\n",
    "    json_path=json_path_template,  # Path to a JSON file containing camera settings template\n",
    "    cal_path=\"\",                  # Path to a pickle file (not used here since it's an empty string)\n",
    "    processing_lvl=-1,            # Processing level (specific to CalibrateCamera, meaning unknown)\n",
    "    exposure_ms=20                # Exposure time in milliseconds\n",
    ") as cam:\n",
    "    \n",
    "    # Retake the flat field image and display it using Holoviews (hvim_flat)\n",
    "    hvim_flat = cam.retake_flat_field(show=True)\n",
    "    hvim_flat.opts(width=600, height=600, axiswise=True)\n",
    "\n",
    "    # Update the row min/max values and display them (hvim_row_minmax)\n",
    "    hvim_row_minmax = cam.update_row_minmax(edgezone=0)\n",
    "    hvim_row_minmax.opts(width=600, height=600, axiswise=True)\n",
    "\n",
    "    # Calculate the window height based on the row slice and ensure it's a multiple of 4 (required for LucidCameras)\n",
    "    windowheight = int(\n",
    "        np.ceil((cam.settings[\"row_slice\"][1] - cam.settings[\"row_slice\"][0]) / 4.0) * 4\n",
    "    )\n",
    "    print(\"Windowheight {}\".format(windowheight))\n",
    "    \n",
    "    # Update camera settings based on the calculated window height:\n",
    "    # - Set the window resolution (height, width)\n",
    "    cam.settings[\"win_resolution\"] = [windowheight + 16, cam.settings[\"resolution\"][1]]\n",
    "    \n",
    "    # - Set the window offset (adjusting for potential padding)\n",
    "    cam.settings[\"win_offset\"] = [\n",
    "        int(np.ceil((cam.settings[\"row_slice\"][0]) / 4.0) * 4) - 8,\n",
    "        cam.settings[\"win_offset\"][1],\n",
    "    ]\n",
    "    \n",
    "    # - Update the row slice (region of interest)\n",
    "    cam.settings[\"row_slice\"] = [16, windowheight - 8]\n",
    "\n",
    "    # Set the overall camera resolution to match the window resolution\n",
    "    cam.settings[\"resolution\"] = cam.settings[\"win_resolution\"]\n",
    "\n",
    "    # Save the updated camera settings to JSON and pickle files\n",
    "    cam.dump(json_path=json_path_target, cal_path=cal_path_target)\n",
    "    \n",
    "# Display the row min/max and flat field images side-by-side using Panel\n",
    "pn.Column(hvim_row_minmax, hvim_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hardware\n",
    "\n",
    "# Initialize the CalibrateCamera class with specified parameters. and setting from previous cell.\n",
    "with CalibrateCamera(\n",
    "    n_lines=50,\n",
    "    processing_lvl=0,\n",
    "    cal_path=cal_path_target,\n",
    "    json_path=json_path_target,\n",
    "    exposure_ms=10,\n",
    ") as cam:\n",
    "    # cam.collect()\n",
    "    cam.start_cam()\n",
    "    img = cam.get_img()\n",
    "    img = cam.crop(img)\n",
    "    cam.stop_cam()\n",
    "    # cam.show(hist_eq=True)\n",
    "\n",
    "# check the window looks ok.\n",
    "hv.Image(img, bounds=(0, 0, *img.shape)).opts(\n",
    "    xlabel=\"wavelength index\",\n",
    "    ylabel=\"cross-track\",\n",
    "    cmap=\"gray\",\n",
    "    title=\"test frame\",\n",
    "    width=400,\n",
    "    height=400,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Take Arc and setup wavelength scale, and get window for 430 to 900nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hardware\n",
    "\n",
    "with CalibrateCamera(\n",
    "    json_path=json_path_target,  # Path to the JSON file with camera settings\n",
    "    cal_path=\"\",                  # Path to a pickle file (not used here)\n",
    "    processing_lvl=-1            # Processing level (specific to CalibrateCamera)\n",
    ") as cam:\n",
    "    \n",
    "    # Set the camera gain value to 10.0 - LUCIDCAMERA ONLY\n",
    "    cam.deviceSettings[\"Gain\"].value = 10.0  \n",
    "\n",
    "    # Capture a HgAr (Mercury-Argon) spectrum image and display it\n",
    "    hvimg = cam.retake_HgAr(show=True, nframes=18)  # Capture 18 frames and average them\n",
    "    hvimg.opts(width=600, height=600)  # Set display options for the image\n",
    "\n",
    "    # Print the maximum pixel value in the captured HgAr image\n",
    "    print(cam.calibration[\"HgAr_pic\"].max()) \n",
    "\n",
    "    # Calculate and update the \"smile\" shifts (geometric distortion correction)\n",
    "    smile_fit_hv = cam.update_smile_shifts()  \n",
    "\n",
    "    # Reset the smile shifts to zero (likely for testing or specific calibration purposes)\n",
    "    cam.calibration[\"smile_shifts\"] = cam.calibration[\"smile_shifts\"] * 0 \n",
    "\n",
    "    # Perform wavelength calibration using the HgAr spectrum\n",
    "    wavefit_hv = cam.fit_HgAr_lines(\n",
    "        top_k=15,                  # Use the top 15 brightest peaks for fitting\n",
    "        brightest_peaks=[546.96, 435.833, (579.960 + 579.066) / 2, 763.511],  # Known HgAr peak wavelengths\n",
    "        find_peaks_height=10,     # Parameters for peak detection \n",
    "        prominence=1,\n",
    "        width=1.5,\n",
    "        interactive_peak_id=True,  # Allow interactive selection of peaks\n",
    "    ) \n",
    "\n",
    "    # Define the desired wavelength range for the \"window\"\n",
    "    waveminmax = [430, 900]  # Wavelength range in nanometers\n",
    "\n",
    "    # Find the corresponding indices in the wavelength array\n",
    "    waveminmax_ind = [\n",
    "        np.argmin(np.abs(cam.calibration[\"wavelengths_linear\"] - λ)) for λ in waveminmax\n",
    "    ]\n",
    "\n",
    "    # Calculate the window width and offset based on the wavelength indices\n",
    "    window_width = int(np.ceil((waveminmax_ind[1] - waveminmax_ind[0] + 8) / 4.0) * 4)\n",
    "    offset_x = int(np.floor((waveminmax_ind[0] - 4) / 4.0) * 4)\n",
    "    print(\"Window Width {}, offset x {}\".format(window_width, offset_x))\n",
    "\n",
    "    # Update camera settings with the new window parameters\n",
    "    cam.settings[\"win_resolution\"][1] = window_width  # Set window width\n",
    "    cam.settings[\"win_offset\"][1] = offset_x        # Set horizontal offset\n",
    "    cam.settings[\"resolution\"] = cam.settings[\"win_resolution\"]  # Update overall resolution\n",
    "\n",
    "    # Display the HgAr image, smile fit data, and wavelength calibration results using Panel\n",
    "    pn.Column(\n",
    "        hvimg,\n",
    "        smile_fit_hv,\n",
    "        wavefit_hv.opts(xlim=(390, 1000), ylim=(-10, 255)).opts(shared_axes=False),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hardware\n",
    "# check the window looks ok.\n",
    "pn.Column(\n",
    "    hvimg.opts(shared_axes=False),\n",
    "    smile_fit_hv.opts(shared_axes=False),\n",
    "    wavefit_hv.opts(xlim=(400, 900), ylim=(-10, 255)).opts(shared_axes=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hardware\n",
    "\n",
    "# save wavefit if things look ok\n",
    "cam.dump(json_path=json_path_target, cal_path=cal_path_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Retake flat field and arc with windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hardware\n",
    "\n",
    "spt.selectPreset(10000)\n",
    "\n",
    "# retake flat frame with wavelegth window set.\n",
    "with CalibrateCamera(\n",
    "    json_path=json_path_target, cal_path=cal_path_target, processing_lvl=-1\n",
    ") as cam:\n",
    "    hvim_flat = cam.retake_flat_field(show=True)\n",
    "    hvim_flat.opts(width=600, height=600, axiswise=True)\n",
    "\n",
    "    hvim_row_minmax = cam.update_row_minmax(edgezone=8)\n",
    "    hvim_row_minmax.opts(width=600, height=600, axiswise=True)\n",
    "\n",
    "    cam.update_resolution()\n",
    "    cam.dump(json_path=json_path_target, cal_path=cal_path_target)\n",
    "\n",
    "spt.turnOffLamp()\n",
    "\n",
    "# display and check all looks ok.\n",
    "hvim_row_minmax + hvim_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redo Arc with window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hardware\n",
    "\n",
    "# retake arc frames and set wavelength scale foir window.\n",
    "\n",
    "with CalibrateCamera(\n",
    "    json_path=json_path_target, cal_path=cal_path_target, processing_lvl=-1\n",
    ") as cam:\n",
    "    cam.deviceSettings[\"Gain\"].value = 15.0\n",
    "    hvimg = cam.retake_HgAr(show=True)\n",
    "\n",
    "    hvimg.opts(width=400, height=400)\n",
    "    print(cam.calibration[\"HgAr_pic\"].max())\n",
    "    smile_fit_hv = cam.update_smile_shifts()\n",
    "\n",
    "    wavefit_hv = cam.fit_HgAr_lines(\n",
    "        top_k=12,\n",
    "        brightest_peaks=[546.96, 435.833, (579.960 + 579.066) / 2, 871.66, 763.511],\n",
    "        find_peaks_height=10,\n",
    "        prominence=1,\n",
    "        width=1.5,\n",
    "        max_match_error=2,\n",
    "        interactive_peak_id=True,\n",
    "    )  # [435.833,546.074,(579.960+579.066)/2,763.511]\n",
    "    \n",
    "    cam.update_intsphere_fit()\n",
    "\n",
    "    cam.dump(json_path=json_path_target, cal_path=cal_path_target)\n",
    "\n",
    "(hvimg + smile_fit_hv + wavefit_hv.opts(xlim=(400, 900), ylim=(-10, 255))).opts(\n",
    "    shared_axes=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get Integrating Sphere data for radiance calibration\n",
    "\n",
    "4D datacube with coordinates of cross-track, wavelength, exposure, and luminance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hardware\n",
    "\n",
    "luminances = np.fromiter(lum_preset_dict.keys(), dtype=int)\n",
    "# luminances = np.append(luminances,0)\n",
    "exposures = [0, 5, 8, 10, 15, 20]\n",
    "\n",
    "with CalibrateCamera(\n",
    "    json_path=json_path_target, cal_path=cal_path_target, processing_lvl=-1\n",
    ") as cam:\n",
    "\n",
    "    cam.calibration[\"rad_ref\"] = cam.update_intsphere_cube(\n",
    "        exposures, luminances, noframe=50, lum_chg_func=spt.selectPreset\n",
    "    )\n",
    "\n",
    "    # remove saturated images\n",
    "    cam.calibration[\"rad_ref\"] = cam.calibration[\"rad_ref\"].where(\n",
    "        ~(\n",
    "            np.sum((cam.calibration[\"rad_ref\"][:, :, :, :, :] == 255), axis=(1, 2))\n",
    "            > 1000\n",
    "        )\n",
    "    )\n",
    "    cam.dump(json_path=json_path_target, cal_path=cal_path_target)\n",
    "\n",
    "spt.turnOffLamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hardware\n",
    "\n",
    "cam.calibration[\"rad_ref\"].plot(\n",
    "    y=\"cross_track\", x=\"wavelength_index\", col=\"exposure\", row=\"luminance\", cmap=\"gray\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hardware\n",
    "\n",
    "print(\"rad_ref is {} MB\".format(cam.calibration[\"rad_ref\"].size / 1024 / 1024 * 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hardware\n",
    "\n",
    "cam.update_intsphere_fit()\n",
    "cam.dump(json_path=json_path_target, cal_path=cal_path_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
